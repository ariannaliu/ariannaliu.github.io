<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhixuan Liu</title>
  
  <meta name="author" content="Zhixuan Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/RI_logo.jpeg">
  <meta name="google-site-verification" content="pSVrU9lbGr90Z7Ojb_9wOWwqZ-DWOa1bx2NBmB7JfO4" />
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:70%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Zhixuan Liu</name>
                </p>
                <p>
                  I am an MSR student working on Generative AI in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> at <a href="http://www.cmu.edu/">Carnegie Mellon University</a>, 
                  advised by Prof. <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a> at roBot Intelligence Group (<a href="https://www.cs.cmu.edu/~./jeanoh/big/">BIG</a>). I also work closely with Dr. <a href="https://frc.ri.cmu.edu/~zhangji/">Ji Zhang</a> and Prof. <a href="https://soonminhwang.github.io/">Soonmin Hwang</a>.
                  Before joining CMU, I received my Bachelor's degree in Computer Science and Engineering from <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a> in 2022.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:zhixuan2@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                  <a href="assets/ZhixuanLiu_Resume_cmu.pdf">CV</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/zhixuan-liu/">LinkedIn</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=aurGzTMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/ariannaliu">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:40%">
                <a href="images/ZhixuanLiu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ZhixuanLiu.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research Interests</heading>
                <p> My research interests lie in the area of generative models and their application in interactive systems. 
                  During my master's thesis, I focused on addressing cultural biases in text-to-image generative models. 
                  Currently, my work involves applying generative models to create simulation environments, particularly in the context of indoor scenes, where simulated robots can navigate and interact in the environment.
                </p> 
                <p><font color="red"><strong>I am seeking PhD positions beginning Fall 2024!</strong></font></p>
              </td>
            </tr>
          </tbody>
         </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="scoft_stop()" onmouseover="scoft_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='scoft_image'>
                    <img src='images/scoft_out.png' width="100%"></div>
                    <img src='images/scoft_in.png' width="100%">
                </div>
                <script type="text/javascript">
                  function scoft_start() {
                    document.getElementById('scoft_image').style.opacity = "1";
                  }

                  function scoft_stop() {
                    document.getElementById('scoft_image').style.opacity = "0";
                  }
                  scoft_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="assets/SCoFT_pdf_github.pdf">
                  <papertitle>SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation</papertitle>
                </a>
                <br>
                <strong>Zhixuan Liu</strong>, 
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>, 
                Beverley-Claire Okogwu, 
                <a href="https://lilydaytoy.github.io/">Wenxuan Peng</a>, 
                Youngsik Yun, 
                <a href="https://ahundt.github.io/">Andrew Hundt</a>, 
                <a href="https://sites.google.com/view/jihiekim">Jihie Kim</a>, 
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>In submission</em>, 2023 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="assets/SCoFT_pdf_github.pdf">Paper</a>
                <p>
                  SCoFT leverages the model's intrinsic biases to refine itself, for the purpose of shifting away from misrepresentations of a culture and achieve equitable image generation.
                </p>
              </td>
            </tr>

            <tr onmouseout="CCUB_stop()" onmouseover="CCUB_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='CCUB_image'>
                    <img src='images/ccub_out.png' width="100%"></div>
                    <img src='images/ccub_in.png' width="100%">
                </div>
                <script type="text/javascript">
                  function CCUB_start() {
                    document.getElementById('CCUB_image').style.opacity = "1";
                  }

                  function CCUB_stop() {
                    document.getElementById('CCUB_image').style.opacity = "0";
                  }
                  CCUB_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/pschaldenbrand/StyleCLIPDraw">
                  <papertitle>Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset</papertitle>
                </a>
                <br>
                <strong>Zhixuan Liu*</strong>, 
                Youeun Shin*, Beverley-Claire Okogwu, Youngsik Yun, 
                <a href="https://www.liacoleman.com/">Lia Coleman</a>, 
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>, 
                <a href="https://sites.google.com/view/jihiekim">Jihie Kim</a>, 
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>AAAI workshop on Creative AI Across Modalities</em>, 2023 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2301.12073">Paper</a>
                /
                <a href="https://github.com/cmubig/CCUB">Code</a>
                <p>
                  Fine-tuning the the text-to-image generative model (Stable Diffusion) and LLM (GPT-3) using our CCUB dataset to achieve culturally-aware text-to-image synthesis.
                </p>
              </td>
            </tr>

            <tr onmouseout="styleclipdraw_stop()" onmouseover="styleclipdraw_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='styleclipdraw_image'>
                    <img src='images/styleclipdraw_out.jpg' width="150"></div>
                    <img src='images/styleclipdraw_in_square.png' width="150">
                </div>
                <script type="text/javascript">
                  function styleclipdraw_start() {
                    document.getElementById('styleclipdraw_image').style.opacity = "1";
                  }

                  function styleclipdraw_stop() {
                    document.getElementById('styleclipdraw_image').style.opacity = "0";
                  }
                  styleclipdraw_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/pschaldenbrand/StyleCLIPDraw">
                  <papertitle>StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Translation</papertitle>
                </a>
                <br>
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>,
                <strong>Zhixuan Liu</strong>,
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2022 <br>
                <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2021 <font color="red"><strong>(Oral)</strong></font><br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2202.12362">Paper</a>
                /
                <a href="https://slideslive.com/38970834/styleclipdraw-coupling-content-and-style-in-texttodrawing-synthesis?ref=account-folder-92044-folders/">Oral Presentation</a>
                /
                <a href="https://github.com/pschaldenbrand/StyleCLIPDraw">Code</a>
                /
                <a href="https://replicate.com/pschaldenbrand/style-clip-draw">Demo</a>
                /
                <a href="https://www.youtube.com/watch?v=5xzcIzHm8Wo">What's AI on YouTube</a>
                <p>
                  StyleCLIPDraw is a text-to-drawing synthesis model with artistic control via a given style image and content control via a language description.
                </p>
              </td>
            </tr>

            <tr onmouseout="clipvideo_stop()" onmouseover="clipvideo_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='clipvideo_image'>
                    <img src='images/clipvideo_demo.gif' width="100%"></div>
                    <img src='images/clipvideo_demo.gif' width="100%">
                </div>
                <script type="text/javascript">
                  function clipvideo_start() {
                    document.getElementById('clipvideo_image').style.opacity = "1";
                  }

                  function clipvideo_start() {
                    document.getElementById('clipvideo_image').style.opacity = "0";
                  }
                  clipvideo_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://pschaldenbrand.github.io/text2video/">
                  <papertitle>Towards Real-Time Text2Video via CLIP-Guided, Pixel-Level Optimization</papertitle>
                </a>
                <br>
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>,
                <strong>Zhixuan Liu</strong>,
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2022<br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2210.12826">Paper</a>
                /
                <a href="https://pschaldenbrand.github.io/text2video/">Project</a>
                /
                <a href="https://replicate.com/pschaldenbrand/text2video">Demo</a>
                /
                <a href="https://github.com/pschaldenbrand/Text2Video">Code</a>
                <p>
                  An approach to generating videos in real-time based on a series of given language descriptions.
                </p>
              </td>
            </tr>


            <tr onmouseout="songbot_stop()" onmouseover="songbot_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='songbot_image'>
                    <img src='images/songbot_in.png' width="150"></div>
                    <img src='images/songbot_in.png' width="150">
                </div>
                <script type="text/javascript">
                  function songbot_start() {
                    document.getElementById('songbot_image').style.opacity = "1";
                  }

                  function songbot_stop() {
                    document.getElementById('songbot_image').style.opacity = "0";
                  }
                  songbot_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/9517454">
                  <papertitle>SongBot: An Interactive Music Generation Robotic System for Non-musicians Learning from a Song</papertitle>
                </a>
                <br>
                <a href="https://crai.cuhk.edu.cn/people/272">Kaiwen Xue</a>,
                <strong>Zhixuan Liu</strong>,
                Jiaying Li,
                <a href="https://airs.cuhk.edu.cn/en/team/766">Xiaoqiang Ji</a>,
                <a href="https://sse.cuhk.edu.cn/en/faculty/qianhuihuan">Huihuan Qian</a>
                <br>
                <em>IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>, 2021 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://ieeexplore.ieee.org/document/9517454">Paper</a>
                /
                <a href="https://drive.google.com/file/d/1NsO0wK6cPPMO9FzcdGY6HN3KAzg-2t4K/view">Video</a>
                <p>
                  SongBot is an interactive music generation system for the non-musician learners to get inspired from a song.
                </p>
              </td>
            </tr>


          </tbody>
        </table>


        


        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Industry Experience</heading>
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/Google_research_logo.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Google Research</strong>, Mountain View, CA, USA
                <br>
                Research Intern & Student Researcher
                <br>
                <i>May - Nov 2020</i>
                <br>
                <p>Research work accepted to ICCV 2021 as an oral presentation</p>
              </td>
            </tr>
          </tbody>
        </table> -->


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Professional Service and Teaching</heading>
              </td>
            </tr>
          </tbody>
        </table>
      
        <table width="90%" align="center" border="0" cellpadding="0">
          <tbody>
            <tr>
              <td width="100%" valign="center">
                <strong>Teaching Assistant</strong>
                <li>PHY1001 Mechanics, 2019 Fall, CUHKSZ</li>  
                <li>CSC3002 Programming Paradigms, 2021 Fall, CUHKSZ</li>  
                <li>CSC4008 Techniques for Data Mining, 2022 Spring, CUHKSZ</li>  
              </td>
            </tr>
          </tbody>
        </table>

        

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Awards and Honors</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="90%" align="center" border="0" cellpadding="0">
          <tbody>
            <tr>
              <td width="100%" valign="center">
                <li>[2022] <strong>Presidential Award for Outstanding Graduates (Top 1%)</strong>, CUHKSZ</li>  
                <li>[2019-2022] <strong>Academic Performance Scholarship</strong>, School of Data Science, CUHKSZ</li> 
                <li>[2019-2022] <strong>Dean's List</strong>, School of Data Science, CUHKSZ</li>  
                <li>[2018] <strong>University Entrance Half Scholarship</strong>, CUHKSZ</li> 
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template from <a href="https://jonbarron.info">Jon Barron</a>. Last updated in Dec 2023.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

      </td>
    </tr>
  </table>
</body>

</html>