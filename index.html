<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhixuan Liu</title>
  
  <meta name="author" content="Zhixuan Liu - CMU">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="Zhixuan Liu, CMU, Carnegie Mellon University, Researcher, Robotics Institute">
  <meta name="description" content="Zhixuan Liu's personal website showcasing projects and research at CMU. Find information on Publications.">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/RI_logo.jpeg">
  <meta name="google-site-verification" content="pSVrU9lbGr90Z7Ojb_9wOWwqZ-DWOa1bx2NBmB7JfO4" />
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:70%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Zhixuan Liu</name>
                </p>
                <p>
                  I am a second year PhD student in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> at <a href="http://www.cmu.edu/">Carnegie Mellon University</a>, 
                  advised by Prof. <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a> and Dr. <a href="https://frc.ri.cmu.edu/~zhangji/">Ji Zhang</a> at roBot Intelligence Group (<a href="https://cmubig.github.io/">BIG</a>).
                  I received a Master's degree in Robotics from CMU in 2024.
                  Before joining CMU, I received my Bachelor's degree in Computer Science and Engineering from <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a> in 2022.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:zhixuan2@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                  <!-- <a href="assets/ZhixuanLiu_Resume_cmu.pdf">CV</a> &nbsp/&nbsp -->
                  <a href="https://www.linkedin.com/in/zhixuan-liu/">LinkedIn</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=aurGzTMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/ariannaliu">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:40%">
                <a href="images/ZhixuanLiu25.jpg"><img style="width:90%;max-width:90%" alt="Zhixuan Liu CMU" src="images/ZhixuanLiu25.jpg" class="hoverZoomLink"></a>
                <!-- <a href="images/ZhixuanLiu2.jpg"><img style="width:100%;max-width:100%" alt="Zhixuan Liu CMU" src="images/ZhixuanLiu2.jpg" class="hoverZoomLink"></a> -->
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research Interests</heading>
                <p> My research interests lie in the area of robotics, generative models and computer vision. 
                </p> 
                <!-- <p><font color="red"><strong>I am seeking PhD positions beginning Fall 2024!</strong></font></p> -->
              </td>
            </tr>
          </tbody>
         </table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="mosaic_stop()" onmouseover="mosaic_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='mosaic_image'>
                    <img src='images/mosaic_out.png' width="100%"></div>
                    <img src='images/mosaic_in.png' width="100%">
                </div>
                <script type="text/javascript">
                  function mosaic_start() {
                    document.getElementById('mosaic_image').style.opacity = "1";
                  }

                  function mosaic_stop() {
                    document.getElementById('mosaic_image').style.opacity = "0";
                  }
                  mosaic_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://mosaic-cmubig.github.io/">
                  <papertitle>MOSAIC: Generating Consistent, Privacy-Preserving Scenes from Multiple Depth Views in Multi-Room Environments</papertitle>
                </a>
                <br>
                <strong>Zhixuan Liu</strong>, 
                <a href="https://zwandering.github.io/">Haokun Zhu</a>,
                <a href="https://ruichen.pub/">Rui Chen</a>,
                <a href="https://scholar.google.com/citations?user=7CLS0LwAAAAJ&hl=en">Jonathan Francis</a>,
                <a href="https://soonminhwang.github.io/">Soonmin Hwang</a>,
                <a href="https://frc.ri.cmu.edu/~zhangji/">Ji Zhang</a>,
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>ICCV</em>, 2025<br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2503.13816">Paper</a>
                /
                <a href="https://mosaic-cmubig.github.io/">Project Page</a>
                /
                <a href="https://mosaic-cmubig.github.io/">Code</a>
                <p>
                  MOSAIC generates multi-view consistent images based on depth prior along robot navigation trajectories. It handles arbitrary viewpoint changes in multi-room environments and generalizes to open vocabulary contexts.
                </p>
              </td>
            </tr>

            <tr onmouseout="scoft_stop()" onmouseover="scoft_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='scoft_image'>
                    <img src='images/scoft_out.png' width="100%"></div>
                    <img src='images/scoft_in.png' width="100%">
                </div>
                <script type="text/javascript">
                  function scoft_start() {
                    document.getElementById('scoft_image').style.opacity = "1";
                  }

                  function scoft_stop() {
                    document.getElementById('scoft_image').style.opacity = "0";
                  }
                  scoft_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ariannaliu.github.io/SCoFT/">
                  <papertitle>SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation</papertitle>
                </a>
                <br>
                <strong>Zhixuan Liu</strong>, 
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>, 
                Beverley-Claire Okogwu, 
                <a href="https://lilydaytoy.github.io/">Wenxuan Peng</a>, 
                Youngsik Yun, 
                <a href="https://ahundt.github.io/">Andrew Hundt</a>, 
                <a href="https://sites.google.com/view/jihiekim">Jihie Kim</a>, 
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>CVPR</em>, 2024 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2401.08053">Paper</a>
                /
                <a href="https://ariannaliu.github.io/SCoFT/">Project Page</a>
                /
                <a href="https://github.com/cmubig/SCoFT">Code</a>
                <p>
                  SCoFT leverages the model's intrinsic biases to refine itself, for the purpose of shifting away from misrepresentations of a culture and achieve equitable image generation.
                </p>
              </td>
            </tr>

            <tr onmouseout="CCUB_stop()" onmouseover="CCUB_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='CCUB_image'>
                    <img src='images/ccub_out.png' width="100%"></div>
                    <img src='images/ccub_in.png' width="100%">
                </div>
                <script type="text/javascript">
                  function CCUB_start() {
                    document.getElementById('CCUB_image').style.opacity = "1";
                  }

                  function CCUB_stop() {
                    document.getElementById('CCUB_image').style.opacity = "0";
                  }
                  CCUB_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2301.12073">
                  <papertitle>Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset</papertitle>
                </a>
                <br>
                <strong>Zhixuan Liu*</strong>, 
                Youeun Shin*, Beverley-Claire Okogwu, Youngsik Yun, 
                <a href="https://www.liacoleman.com/">Lia Coleman</a>, 
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>, 
                <a href="https://sites.google.com/view/jihiekim">Jihie Kim</a>, 
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>AAAI workshop on Creative AI Across Modalities</em>, 2023 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2301.12073">Paper</a>
                /
                <a href="https://github.com/cmubig/CCUB">Code</a>
                <p>
                  Fine-tuning the the text-to-image generative model (Stable Diffusion) and LLM (GPT-3) using our CCUB dataset to achieve culturally-aware text-to-image synthesis.
                </p>
              </td>
            </tr>

            <tr onmouseout="styleclipdraw_stop()" onmouseover="styleclipdraw_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='styleclipdraw_image'>
                    <img src='images/styleclipdraw_out.jpg' width="150"></div>
                    <img src='images/styleclipdraw_in_square.png' width="150">
                </div>
                <script type="text/javascript">
                  function styleclipdraw_start() {
                    document.getElementById('styleclipdraw_image').style.opacity = "1";
                  }

                  function styleclipdraw_stop() {
                    document.getElementById('styleclipdraw_image').style.opacity = "0";
                  }
                  styleclipdraw_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/pschaldenbrand/StyleCLIPDraw">
                  <papertitle>StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Translation</papertitle>
                </a>
                <br>
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>,
                <strong>Zhixuan Liu</strong>,
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>IJCAI</em>, 2022 <br>
                <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2021 <font color="red"><strong>(Oral)</strong></font><br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2202.12362">Paper</a>
                /
                <a href="https://slideslive.com/38970834/styleclipdraw-coupling-content-and-style-in-texttodrawing-synthesis?ref=account-folder-92044-folders/">Oral Presentation</a>
                /
                <a href="https://github.com/pschaldenbrand/StyleCLIPDraw">Code</a>
                /
                <a href="https://replicate.com/pschaldenbrand/style-clip-draw">Demo</a>
                /
                <a href="https://www.youtube.com/watch?v=5xzcIzHm8Wo">What's AI on YouTube</a>
                <p>
                  StyleCLIPDraw is a text-to-drawing synthesis model with artistic control via a given style image and content control via a language description.
                </p>
              </td>
            </tr>

            <tr onmouseout="clipvideo_stop()" onmouseover="clipvideo_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='clipvideo_image'>
                    <img src='images/clipvideo_demo.gif' width="100%"></div>
                    <img src='images/clipvideo_demo.gif' width="100%">
                </div>
                <script type="text/javascript">
                  function clipvideo_start() {
                    document.getElementById('clipvideo_image').style.opacity = "1";
                  }

                  function clipvideo_start() {
                    document.getElementById('clipvideo_image').style.opacity = "0";
                  }
                  clipvideo_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://pschaldenbrand.github.io/text2video/">
                  <papertitle>Towards Real-Time Text2Video via CLIP-Guided, Pixel-Level Optimization</papertitle>
                </a>
                <br>
                <a href="https://pschaldenbrand.github.io/">Peter Schaldenbrand</a>,
                <strong>Zhixuan Liu</strong>,
                <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
                <br>
                <em>NeurIPS Workshop on Machine Learning for Creativity and Design</em>, 2022<br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://arxiv.org/abs/2210.12826">Paper</a>
                /
                <a href="https://pschaldenbrand.github.io/text2video/">Project Page</a>
                /
                <a href="https://replicate.com/pschaldenbrand/text2video">Demo</a>
                /
                <a href="https://github.com/pschaldenbrand/Text2Video">Code</a>
                <p>
                  An approach to generating videos in real-time based on a series of given language descriptions.
                </p>
              </td>
            </tr>


            <tr onmouseout="songbot_stop()" onmouseover="songbot_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='songbot_image'>
                    <img src='images/songbot_in.png' width="150"></div>
                    <img src='images/songbot_in.png' width="150">
                </div>
                <script type="text/javascript">
                  function songbot_start() {
                    document.getElementById('songbot_image').style.opacity = "1";
                  }

                  function songbot_stop() {
                    document.getElementById('songbot_image').style.opacity = "0";
                  }
                  songbot_stop()
                </script>
              </td>
              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/9517454">
                  <papertitle>SongBot: An Interactive Music Generation Robotic System for Non-musicians Learning from a Song</papertitle>
                </a>
                <br>
                <a href="https://crai.cuhk.edu.cn/people/272">Kaiwen Xue</a>,
                <strong>Zhixuan Liu</strong>,
                Jiaying Li,
                <a href="https://airs.cuhk.edu.cn/en/team/766">Xiaoqiang Ji</a>,
                <a href="https://sse.cuhk.edu.cn/en/faculty/qianhuihuan">Huihuan Qian</a>
                <br>
                <em>IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>, 2021 <br>
                <!-- <font color="red"><strong>Oral Presentation</strong></font> -->
                <a href="https://ieeexplore.ieee.org/document/9517454">Paper</a>
                /
                <a href="https://drive.google.com/file/d/1NsO0wK6cPPMO9FzcdGY6HN3KAzg-2t4K/view">Video</a>
                <p>
                  SongBot is an interactive music generation system for the non-musician learners to get inspired from a song.
                </p>
              </td>
            </tr>


          </tbody>
        </table>


        


        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Industry Experience</heading>
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/Google_research_logo.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Google Research</strong>, Mountain View, CA, USA
                <br>
                Research Intern & Student Researcher
                <br>
                <i>May - Nov 2020</i>
                <br>
                <p>Research work accepted to ICCV 2021 as an oral presentation</p>
              </td>
            </tr>
          </tbody>
        </table> -->


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Professional Service and Teaching</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="90%" align="center" border="0" cellpadding="0">
          <tbody>
            <tr>
              <td width="100%" valign="center">
                <strong>Teaching Assistant</strong>
                <li>16-726 <a href="https://learning-image-synthesis.github.io/sp25/">Learning-Based Image Synthesis</a>, Spring 2025, CMU</li>
                <li>CSC4008 Techniques for Data Mining, Spring 2022, CUHKSZ</li>  
                <li>CSC3002 Programming Paradigms, Fall 2021, CUHKSZ</li>  
                <li>PHY1001 Mechanics, Fall 2019, CUHKSZ</li>  
              </td>
            </tr>
          </tbody>
        </table>

        

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Awards and Honors</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="90%" align="center" border="0" cellpadding="0">
          <tbody>
            <tr>
              <td width="100%" valign="center">
                <li>[2025-2026] <strong>Northrop Grumman Fellowship</strong>, CMU RI</li>  
                <li>[2022] <strong>Presidential Award for Outstanding Graduates (Top 1%)</strong>, CUHKSZ</li>  
                <li>[2019-2022] <strong>Academic Performance Scholarship</strong>, School of Data Science, CUHKSZ</li> 
                <li>[2019-2022] <strong>Dean's List</strong>, School of Data Science, CUHKSZ</li>  
                <li>[2018] <strong>University Entrance Half Scholarship</strong>, CUHKSZ</li> 
              </td>
            </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template from <a href="https://jonbarron.info">Jon Barron</a>. Last updated in August 2025.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

      </td>
    </tr>
  </table>
</body>

</html>
